{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2152 images belonging to 3 classes.\n",
      "Found 601 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "img_rows, img_cols = 150, 150\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir=\"./dataset/train\"\n",
    "validation_data_dir=\"./dataset/test\"\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=30,\n",
    "                                 width_shift_range=0.3,\n",
    "                                 height_shift_range=0.3,\n",
    "                                 horizontal_flip=True,\n",
    "                                 fill_mode='nearest')\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                 target_size=(img_rows,img_cols),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "validation_generator=validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                           target_size=(img_rows,img_cols),\n",
    "                                                           batch_size=batch_size,\n",
    "                                                           class_mode='categorical')\n",
    "\n",
    "\n",
    "                                 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 150, 150, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                1327168   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,508,131\n",
      "Trainable params: 2,505,955\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', kernel_initializer=\"he_normal\",\n",
    "                 input_shape = (img_rows, img_cols, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\", kernel_initializer=\"he_normal\", \n",
    "                 input_shape = (img_rows, img_cols, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #2: second CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #3: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #4: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #5: first set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #6: second set of FC => RELU layers\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #7: softmax classifier\n",
    "model.add(Dense(num_classes, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 64/134 [=============>................] - ETA: 2:22 - loss: 1.3481 - accuracy: 0.5364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upjab\\Anaconda3\\envs\\jabir\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 240s 2s/step - loss: 1.2771 - accuracy: 0.5698 - val_loss: 0.1904 - val_accuracy: 0.4764\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19041, saving model to ./checkpoint/objcheck8.h5\n",
      "Epoch 2/50\n",
      "134/134 [==============================] - 207s 2s/step - loss: 0.9965 - accuracy: 0.6545 - val_loss: 0.0806 - val_accuracy: 0.6940\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19041 to 0.08061, saving model to ./checkpoint/objcheck8.h5\n",
      "Epoch 3/50\n",
      "134/134 [==============================] - 216s 2s/step - loss: 0.9469 - accuracy: 0.6798 - val_loss: 0.7144 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08061\n",
      "Epoch 4/50\n",
      "134/134 [==============================] - 204s 2s/step - loss: 0.9128 - accuracy: 0.6845 - val_loss: 0.9252 - val_accuracy: 0.8308\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08061\n",
      "Epoch 5/50\n",
      "134/134 [==============================] - 207s 2s/step - loss: 0.8469 - accuracy: 0.7079 - val_loss: 0.3646 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08061\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./checkpoint/objcheck8.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop=EarlyStopping(monitor='val_loss',\n",
    "                       min_delta=0,\n",
    "                       patience=3,\n",
    "                       verbose=1,\n",
    "                       restore_best_weights=True)\n",
    "\n",
    "reduce_lr=ReduceLROnPlateau(monitor='val_loss',\n",
    "                           factor=0.2,\n",
    "                           patience=3,\n",
    "                           verbose=1,\n",
    "                           min_delta=0.0001)\n",
    "\n",
    "callbacks=[checkpoint,earlystop,reduce_lr]\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=RMSprop(lr=0.0001),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "nb_train_samples=2152\n",
    "nb_validation_samples=600\n",
    "epochs=50\n",
    "\n",
    "history=model.fit_generator(train_generator,\n",
    "                           steps_per_epoch = nb_train_samples // batch_size,\n",
    "                           epochs = epochs,\n",
    "                           callbacks =callbacks,\n",
    "                           validation_data=validation_generator,\n",
    "                           validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 601 images belonging to 3 classes.\n",
      "Confusion Matrix\n",
      "[[134  27  39]\n",
      " [  6 111  83]\n",
      " [ 18   9 174]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Accident       0.85      0.67      0.75       200\n",
      "        Fire       0.76      0.56      0.64       200\n",
      "      Knives       0.59      0.87      0.70       201\n",
      "\n",
      "    accuracy                           0.70       601\n",
      "   macro avg       0.73      0.70      0.70       601\n",
      "weighted avg       0.73      0.70      0.70       601\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "nb_train_samples = 2152\n",
    "nb_validation_samples = 600\n",
    "\n",
    "# We need to recreate our validation generator with shuffle = false\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 601 images belonging to 3 classes.\n",
      "Confusion Matrix\n",
      "[[190  10   0]\n",
      " [ 21 176   3]\n",
      " [ 26   8 167]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Accident       0.80      0.95      0.87       200\n",
      "        Fire       0.91      0.88      0.89       200\n",
      "      Knives       0.98      0.83      0.90       201\n",
      "\n",
      "    accuracy                           0.89       601\n",
      "   macro avg       0.90      0.89      0.89       601\n",
      "weighted avg       0.90      0.89      0.89       601\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "nb_train_samples = 2152\n",
    "nb_validation_samples = 600\n",
    "\n",
    "# We need to recreate our validation generator with shuffle = false\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 601 images belonging to 3 classes.\n",
      "{0: 'Accident', 1: 'Fire', 2: 'Knives'}\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "def draw_test(name, pred, im, true_label):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 160, 0, 0, 500 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, \"predited - \"+ pred, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.putText(expanded_image, \"true - \"+ true_label, (20, 120) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "\n",
    "def getRandomImage(path, img_width, img_height):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    final_path = file_path + \"/\" + image_name\n",
    "    return image.load_img(final_path, target_size = (img_width, img_height)), final_path, path_class\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "\n",
    "files = []\n",
    "predictions = []\n",
    "true_labels = []\n",
    "# predicting images\n",
    "for i in range(0, 10):\n",
    "    path = \"./dataset/test/\" \n",
    "    img, final_path, true_label = getRandomImage(path, img_width, img_height)\n",
    "    files.append(final_path)\n",
    "    true_labels.append(true_label)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x * 1./255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict_classes(images, batch_size = 10)\n",
    "    predictions.append(classes)\n",
    "    \n",
    "for i in range(0, len(files)):\n",
    "    image = cv2.imread((files[i]))\n",
    "    draw_test(\"Prediction\", class_labels[predictions[i][0]], image, true_labels[i])\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##single_image from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import models\n",
    "\n",
    "#Load the saved model\n",
    "model = models.load_model(\"./checkpoint/objcheck8.h5\")\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "        _, frame = video.read()\n",
    "\n",
    "        #Convert the captured frame into RGB\n",
    "        im = Image.fromarray(frame, 'RGB')\n",
    "\n",
    "        #Resizing into 128x128 because we trained the model with this image size.\n",
    "        im = im.resize((150,150))\n",
    "        img_array = np.array(im)\n",
    "\n",
    "        #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "        #So changing dimension 128x128x3 into 1x128x128x3 \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        #Calling the predict method on model to predict 'me' on the image\n",
    "        prediction = int(model.predict(img_array)[0][0])\n",
    "        print(prediction)\n",
    "        #if prediction is 0, which means I am missing on the image, then show the frame in gray color.\n",
    "        if prediction == 0:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        key=cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "                break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}